<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Sensor Test</title>
  <style>
    body { font-family: system-ui, -apple-system, Segoe UI, Roboto, sans-serif; margin: 2rem; }
    #status { margin-bottom: 1rem; }
    .reading { font-size: 1.6rem; margin: .5rem 0; }
    button { font-size: 1rem; padding: .6rem 1rem; margin: .5rem; }
    #camera-container { margin-top: 2rem; }
    #video { 
      width: 100%; 
      max-width: 400px; 
      border: 2px solid #ccc; 
      border-radius: 8px;
      display: none;
    }
    #canvas { display: none; }
    #camera-status { 
      font-size: 0.9rem; 
      color: #666; 
      margin-top: 0.5rem; 
    }
    .controls { margin: 1rem 0; }
    .bbox {
      position: absolute;
      border: 2px solid #28a745;
      pointer-events: none;
      box-shadow: 0 0 4px #28a745;
    }
    #video-wrapper {
      position: relative;
      display: inline-block;
    }
    #overlay {
      position: absolute;
      left: 0;
      top: 0;
      pointer-events: none;
    }
  </style>
</head>
<body>
  <h1>iPhone Sensor Test</h1>
  <div id="status">Tap "Enable sensors" on iPhone Safari.</div>
  
  <div class="controls">
    <button id="btn">Enable sensors</button>
    <button id="camera-btn">Start Camera</button>
    <button id="stop-camera-btn" style="display: none;">Stop Camera</button>
  </div>
  
  <div class="reading">Pitch: <span id="pitch">—</span>°</div>
  <div class="reading">Roll: <span id="roll">—</span>°</div>
  <div class="reading">Raw β (beta): <span id="beta">—</span>°</div>
  <div class="reading">Raw γ (gamma): <span id="gamma">—</span>°</div>
  <div class="reading">Golf Ball Detected: <span id="golf-ball-status">—</span></div>

  <div id="camera-container">
    <h2>Live Camera Feed</h2>
    <div id="video-wrapper">
      <video id="video" autoplay playsinline></video>
      <canvas id="overlay"></canvas>
    </div>
    <canvas id="canvas"></canvas>
    <div id="camera-status">Camera not started</div>
    <div id="detection-details" style="font-size: 0.8rem; color: #666; margin-top: 0.5rem;"></div>
  </div>

  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.16.0/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd@2.2.3/dist/coco-ssd.min.js"></script>
  <script>
    const pitchEl = document.getElementById('pitch');
    const rollEl  = document.getElementById('roll');
    const betaEl  = document.getElementById('beta');
    const gammaEl = document.getElementById('gamma');
    const statusEl= document.getElementById('status');
    
    // Camera elements
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const overlay = document.getElementById('overlay');
    const cameraStatus = document.getElementById('camera-status');
    const cameraBtn = document.getElementById('camera-btn');
    const stopCameraBtn = document.getElementById('stop-camera-btn');
    
    // Golf ball detection elements
    const golfBallStatus = document.getElementById('golf-ball-status');
    const detectionDetails = document.getElementById('detection-details');
    
    // Camera state
    let stream = null;
    let uploadInterval = null;
    let frameCount = 0;

    // Simple low-pass filter for accel
    let ax=0, ay=0, az=0, alpha=0.1;

    // TensorFlow.js detector
    let detectorModel = null;
    let detectorReady = false;
    let lastDetections = [];

    function startListeners() {
      // Preferred: compute pitch/roll from accelerationIncludingGravity (more stable)
      window.addEventListener('devicemotion', (e) => {
        if (!e.accelerationIncludingGravity) return;
        const g = e.accelerationIncludingGravity;
        ax = alpha*g.x + (1-alpha)*ax;
        ay = alpha*g.y + (1-alpha)*ay;
        az = alpha*g.z + (1-alpha)*az;

        // Pitch/roll (radians)
        const pitch = Math.atan2(-ax, Math.hypot(ay, az));
        const roll  = Math.atan2( ay, az);

        pitchEl.textContent = (pitch * 180/Math.PI).toFixed(1);
        rollEl.textContent  = (roll  * 180/Math.PI).toFixed(1);
      });

      // Also show raw orientation (beta/gamma) for reference
      window.addEventListener('deviceorientation', (e) => {
        if (e.beta != null) betaEl.textContent  = e.beta.toFixed(1);
        if (e.gamma!= null) gammaEl.textContent = e.gamma.toFixed(1);
      });

      statusEl.textContent = 'Sensors active.';
    }

    async function enableSensors() {
      try {
        // iOS requires user gesture + permission calls
        const needsPermDM = typeof DeviceMotionEvent !== 'undefined' && typeof DeviceMotionEvent.requestPermission === 'function';
        const needsPermDO = typeof DeviceOrientationEvent !== 'undefined' && typeof DeviceOrientationEvent.requestPermission === 'function';

        if (needsPermDM) {
          const res = await DeviceMotionEvent.requestPermission();
          if (res !== 'granted') throw new Error('DeviceMotion denied');
        }
        if (needsPermDO) {
          const res2 = await DeviceOrientationEvent.requestPermission();
          if (res2 !== 'granted') throw new Error('DeviceOrientation denied');
        }
        startListeners();
      } catch (err) {
        statusEl.textContent = 'Permission error: ' + err.message + '. In Settings > Safari, enable "Motion & Orientation Access," then reload over HTTPS.';
      }
    }

    async function loadDetector() {
      cameraStatus.textContent = 'Loading detector...';
      try {
        detectorModel = await cocoSsd.load({ base: 'lite_mobilenet_v2' }); // lightweight
        detectorReady = true;
        cameraStatus.textContent = 'Detector loaded. Start camera.';
      } catch (e) {
        console.error('Detector load failed', e);
        cameraStatus.textContent = 'Detector load failed (continuing without)';
      }
    }
    loadDetector();

    async function runDetection() {
      if (!detectorReady || video.readyState !== 4) return;
      // Run every 4th frame to reduce load
      if (frameCount % 4 !== 0) return;
      try {
        const preds = await detectorModel.detect(video);
        // Filter for 'sports ball'
        lastDetections = preds
          .filter(p => p.class === 'sports ball' && p.score >= 0.55)
          .map(p => ({
            class: p.class,
            confidence: p.score,
            bbox: p.bbox  // [x, y, width, height]
          }));
        drawDetections();
        updateDetectionUIFromClient();
      } catch (e) {
        console.warn('Detection error', e);
      }
    }

    function drawDetections() {
      overlay.width = video.videoWidth || 640;
      overlay.height = video.videoHeight || 480;
      const ctx = overlay.getContext('2d');
      ctx.clearRect(0, 0, overlay.width, overlay.height);
      lastDetections.forEach(det => {
        const [x, y, w, h] = det.bbox;
        ctx.strokeStyle = '#28a745';
        ctx.lineWidth = 2;
        ctx.strokeRect(x, y, w, h);
        ctx.fillStyle = 'rgba(40,167,69,0.2)';
        ctx.fillRect(x, y, w, h);
        ctx.fillStyle = '#fff';
        ctx.font = '12px sans-serif';
        ctx.fillText(`${(det.confidence*100).toFixed(0)}%`, x + 4, y + 14);
      });
    }

    function updateDetectionUIFromClient() {
      if (lastDetections.length > 0) {
        golfBallStatus.textContent = `YES (${lastDetections.length})`;
        golfBallStatus.style.color = '#28a745';
        detectionDetails.innerHTML = lastDetections.map((d, i) => {
          const diameterApprox = Math.min(d.bbox[2], d.bbox[3]);
          return `Ball ${i+1}: ~${diameterApprox.toFixed(1)}px dia, conf ${(d.confidence*100).toFixed(1)}% (client)`;
        }).join('<br>');
      } else {
        golfBallStatus.textContent = 'NO';
        golfBallStatus.style.color = '#dc3545';
        detectionDetails.textContent = 'No golf balls detected (client)';
      }
    }

    async function startCamera() {
      try {
        // Request camera access with rear camera preference
        stream = await navigator.mediaDevices.getUserMedia({
          video: { 
            facingMode: 'environment', // Use rear camera
            width: { ideal: 640 },
            height: { ideal: 480 }
          }
        });
        
        video.srcObject = stream;
        video.style.display = 'block';
        overlay.style.display = 'block';
        
        // Setup canvas for image capture
        canvas.width = 640;
        canvas.height = 480;
        overlay.width = 640;
        overlay.height = 480;
        
        cameraStatus.textContent = 'Camera active - uploading 2 fps';
        cameraBtn.style.display = 'none';
        stopCameraBtn.style.display = 'inline-block';
        
        // Start uploading frames every 500ms (2 fps)
        uploadInterval = setInterval(captureAndUpload, 500);
        
      } catch (err) {
        cameraStatus.textContent = 'Camera error: ' + err.message;
        console.error('Camera access error:', err);
      }
    }

    function stopCamera() {
      if (stream) {
        stream.getTracks().forEach(track => track.stop());
        stream = null;
      }
      
      if (uploadInterval) {
        clearInterval(uploadInterval);
        uploadInterval = null;
      }
      
      video.style.display = 'none';
      cameraStatus.textContent = 'Camera stopped';
      cameraBtn.style.display = 'inline-block';
      stopCameraBtn.style.display = 'none';
      frameCount = 0;
    }

    function captureAndUpload() {
      if (!video.videoWidth || !video.videoHeight) return;
      
      // Draw current video frame to canvas
      const ctx = canvas.getContext('2d');
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

      // Run client-side detection (non-blocking heavy operations minimized)
      runDetection();

      // Convert to blob and upload
      canvas.toBlob(async (blob) => {
        try {
          frameCount++;
          
          // Create form data
          const formData = new FormData();
          formData.append('image', blob, `frame_${frameCount}_${Date.now()}.jpg`);
          formData.append('timestamp', Date.now().toString());
          formData.append('frame_number', frameCount.toString());
          
          // Add sensor data if available
          if (pitchEl.textContent !== '—') {
            formData.append('pitch', pitchEl.textContent);
            formData.append('roll', rollEl.textContent);
          }
          
          // Attach client detections summary
          if (lastDetections.length) {
            formData.append('client_detections', JSON.stringify(lastDetections));
          }

          // Upload to server
          const response = await fetch('/upload_frame', {
            method: 'POST',
            body: formData
          });
          
          if (response.ok) {
            const result = await response.json();
            
            // Update camera status
            cameraStatus.textContent = `Camera active - frame ${frameCount} uploaded`;
            
            // Optionally reconcile server detections (currently empty)
            if (result.golf_balls && result.golf_balls.length > 0) {
              // Could merge or display separately; leaving client result prioritized
            }
          } else {
            cameraStatus.textContent = `Upload error: ${response.status}`;
          }
        } catch (err) {
          cameraStatus.textContent = 'Upload failed: ' + err.message;
          console.error('Upload error:', err);
        }
      }, 'image/jpeg', 0.8);
    }

    // Event listeners
    document.getElementById('btn').addEventListener('click', enableSensors);
    cameraBtn.addEventListener('click', startCamera);
    stopCameraBtn.addEventListener('click', stopCamera);
  </script>
</body>
</html>